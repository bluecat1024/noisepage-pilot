# "Skynet" - Configuration to generate an entire modeling pipeline.
skynet:
  workload_generate: False
  workload_execute: False
  workload_process: False
  workload_filters: ["*"]

  # List of models to train in format [experiment/<data_path>, models/<output_name>/, use_featurewiz].
  train_models:
    - [tpcc_sf1, "tpcc_sf1", False]

  # evals_ou in format [experiment/<data_path>, models/<model_name>/, evals_ou/<output_name>/].
  evals_ou:
    - [tpcc_sf1, "tpcc_sf1", "tpcc_sf1_evals"]

  eval_query:
    - benchmark: tpcc
      user: wz2
      restore_db_path: ~/pg_dumps/tpcc_sf1.dir
      pg_conf_path: config/postgres/default_postgresql.conf
      num_iterations: [1]
      predictive: [True]
      session_path: [session.sql]
      model_subdir: ["tpcc_sf1/gbm_l2/"]
      raw_data: ["tpcc_sf1"]
      output_paths: ["tpcc_sf1_query_evals"]

  eval_query_plots: True

  # List of models to train in format [experiment/<data_path>, models/<output_name>/, use_featurewiz].
  train_workload_models:
    - output: "workload_model"
      inputs:
        # Inputs are tuple pairs [experiment/<data_path>, benchmark]
        - ["tpcc_sf1", "tpcc"]
      epochs: 1000
      separate: False
      hidden_size: 256
      batch_size: 1000000

  eval_query_workload:
    - benchmark: tpcc
      user: wz2
      restore_db_path: ~/pg_dumps/tpcc_sf1.dir
      pg_conf_path: config/postgres/default_postgresql.conf
      session_path: session.sql
      slice_window: 10000
      raw_data: "tpcc_sf1"
      model_subdir: "tpcc_sf1/gbm_l2/"
      workload_model: "workload_model"
      output_paths: "tpcc_sf1_query_workload_evals"
      preserve_scratch: False
  eval_query_workload_plots: True

  output_path: /home/wz2/evaluation_0/
  zip_data: False
  zip_models: False
  zip_workload_models: False
  zip_evals_ou: False
  zip_eval_query: False
  zip_eval_query_plots: False
  zip_eval_query_workload: False
  zip_eval_query_workload_plots: False
